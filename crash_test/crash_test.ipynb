{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ResNetForImageClassification, DetrImageProcessor, DetrForObjectDetection\n",
    "import torch\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_names_from_file_name(file_name):\n",
    "    regex = r'([^_]+)_\\d+\\w\\+([^_]+)_\\d+\\w'\n",
    "    matches = re.findall(regex, file_name)\n",
    "\n",
    "    if matches and len(matches) == 1:\n",
    "        answer1, answer2 = matches[0]\n",
    "        return [answer1, answer2]\n",
    "\n",
    "    return []\n",
    "\n",
    "def get_file_list(directory):\n",
    "    answers_list = []\n",
    "    file_list = []\n",
    "    for file in os.listdir(directory):\n",
    "        answers_list.append(extract_names_from_file_name(file))\n",
    "        # replace is for windows\n",
    "        file_list.append(os.path.join(directory, file).replace(\"\\\\\",\"/\"))\n",
    "    return file_list, answers_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "file_list, answers_list = get_file_list('../res/generated')\n",
    "\n",
    "# randomize list\n",
    "zipped_list = list(zip(file_list, answers_list))\n",
    "random.shuffle(zipped_list)\n",
    "file_list, answers_list = zip(*zipped_list)\n",
    "\n",
    "# print(file_list[:10], answers_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N = 10000 # number of images to open\n",
    "\n",
    "images_list = []\n",
    "for file_name in file_list[:N]:\n",
    "    # Open the image file\n",
    "    try:\n",
    "        image = Image.open(file_name)\n",
    "        images_list.append(image)\n",
    "    except IOError:\n",
    "        print(f\"Failed to open {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet:\n",
    "    def __init__(self):\n",
    "        self.processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "        self.model = ResNetForImageClassification.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "    def test(self, images_list, answers_list):\n",
    "        print(\"=============================================== ResNet50 Tests =================================================================\")\n",
    "        tot_found = 0\n",
    "        for i, image in enumerate(images_list):\n",
    "            inputs = self.processor(image, return_tensors=\"pt\")\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                logits = self.model(**inputs).logits\n",
    "            # model predicts one of the 1000 ImageNet classes\n",
    "            # predicted_label = logits.argmax(-1).item()\n",
    "            predicted_label = torch.argsort(logits)\n",
    "            classifications = []\n",
    "            found_1 = False\n",
    "            found_2 = False\n",
    "            result = f\"Answers = {answers_list[i]};\\t\\t\\tFound: \"\n",
    "\n",
    "            # tries the 5 most probable inferences\n",
    "            for j in range(0,5):\n",
    "                labels = self.model.config.id2label[predicted_label[0][j].item()].split(\", \")\n",
    "                for label in labels:\n",
    "                    classifications.append(label)\n",
    "                if answers_list[i][0] in labels:\n",
    "                    found_1 = True \n",
    "                    result += f\"{answers_list[i][0]} as n.{j+1} with highest probability; \"\n",
    "                    tot_found += 1\n",
    "                if answers_list[i][1] in labels:\n",
    "                    found_2 = True\n",
    "                    result += f\"{answers_list[i][1]} as n.{j+1} with highest probability; \"\n",
    "                    tot_found += 1\n",
    "            if not found_1 and not found_2:\n",
    "                result += f\"NONE (classified as {classifications[:3]});\"\n",
    "                \n",
    "            print(result)           \n",
    "        print(\"=================================================================================================================================\")\n",
    "        print(f\"Images analysed: {len(images_list)}; subjects recognized: {tot_found}.\")\n",
    "        print(\"=================================================================================================================================\\n\\n\")\n",
    "\n",
    "class Detr_ResNet:\n",
    "    def __init__(self):\n",
    "        self.processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "        self.model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "\n",
    "\n",
    "    def test(self, images_list, answers_list):\n",
    "        one_found = 0\n",
    "        both_found = 0\n",
    "        print(\"============================================== DETR-ResNet50 Tests ==============================================================\")\n",
    "        for i, image in enumerate(images_list):\n",
    "            inputs = self.processor(image, return_tensors=\"pt\")\n",
    "            \n",
    "            outputs = self.model(**inputs)\n",
    "            \n",
    "            found_1 = False\n",
    "            found_2 = False\n",
    "            result = f\"Answers = {answers_list[i]};\\t\\t\\tFound: \"\n",
    "\n",
    "            # convert outputs (bounding boxes and class logits) to COCO API\n",
    "            # let's only keep detections with score > 0.9\n",
    "            target_sizes = torch.tensor([image.size[::-1]])\n",
    "            output = self.processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n",
    "            labels = []\n",
    "            scores = []\n",
    "            for score, label in zip(output[\"scores\"], output[\"labels\"]):\n",
    "                output_label = self.model.config.id2label[label.item()]\n",
    "                labels.append(output_label)\n",
    "                scores.append(round(score.item(), 3))\n",
    "                if answers_list[i][0] == output_label:\n",
    "                    found_1 = True \n",
    "                    result += f\"{answers_list[i][0]} (detected with confidence {round(score.item(), 3)}); \"\n",
    "                if answers_list[i][1] == output_label:\n",
    "                    found_2 = True\n",
    "                    result += f\"{answers_list[i][1]} (detected with confidence {round(score.item(), 3)}); \"\n",
    "            if answers_list[i][0] in labels or answers_list[i][1] in labels:\n",
    "                one_found += 1\n",
    "            if answers_list[i][0] in labels and answers_list[i][1] in labels:\n",
    "                both_found += 1\n",
    "            \n",
    "\n",
    "            if not found_1 and not found_2:\n",
    "                result += f\"NONE ({labels} detected with confidence {scores});\"\n",
    "            print(result)           \n",
    "        print(\"=================================================================================================================================\")\n",
    "        print(f\"Images analysed: {len(images_list)}; at least one subject recognized: {one_found}; both subjects recognized: {both_found}.\")\n",
    "        print(f\"\\t\\t     at least one subject recognized: {one_found/len(images_list)*100}%; both subjects recognized: {both_found/len(images_list)*100}%.\")\n",
    "        print(\"=================================================================================================================================\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet()\n",
    "detr_resnet = Detr_ResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# resnet.test(images_list, answers_list)\n",
    "detr_resnet.test(images_list, answers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
